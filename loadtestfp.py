# -*- coding: utf-8 -*-
"""LoadTestFP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KEyJQ315e4jkkXFXOeBaOcBAq8pfo5ke
"""

import pandas as pd
from google.colab import drive
drive.mount("/content/drive")
data=pd.read_csv("/content/drive/MyDrive/stdataset.csv", low_memory=False)
#importing dataset
display(data)

data.drop(columns=[ "timeStamp","failureMessage" , "allThreads","responseMessage","IdleTime"], inplace=True)
# dropping irrelevant columns
display(data)

data['responseCode'].replace('Non HTTP response code: org.apache.http.conn.HttpHostConnectException', '500', inplace=True)
#Encoding 500 for HIGH Load

import numpy as np

# Convert 'elapsed' column to numeric, coercing non-numeric values to NaN
data['elapsed'] = pd.to_numeric(data['elapsed'], errors='coerce')
# Replace NaN values with np.nan
data.loc[pd.isna(data['elapsed']), 'elapsed'] = np.nan
# Convert 'elapsed' column to int64 datatype
data['elapsed'] = data['elapsed'].astype('Int64')


data['responseCode'] = pd.to_numeric(data['responseCode'], errors='coerce')
data.loc[pd.isna(data['responseCode']), 'responseCode'] = np.nan
data['responseCode'] = data['responseCode'].astype('Int64')

data['bytes'] = pd.to_numeric(data['bytes'], errors='coerce')
data.loc[pd.isna(data['bytes']), 'bytes'] = np.nan
data['bytes'] = data['bytes'].astype('Int64')

data['sentBytes'] = pd.to_numeric(data['sentBytes'], errors='coerce')
data.loc[pd.isna(data['sentBytes']), 'sentBytes'] = np.nan
data['sentBytes'] = data['sentBytes'].astype('Int64')

data['grpThreads'] = pd.to_numeric(data['grpThreads'], errors='coerce')
data.loc[pd.isna(data['grpThreads']), 'grpThreads'] = np.nan
data['grpThreads'] = data['grpThreads'].astype('Int64')

data['Latency'] = pd.to_numeric(data['Latency'], errors='coerce')
data.loc[pd.isna(data['Latency']), 'Latency'] = np.nan
data['Latency'] = data['Latency'].astype('Int64')

data['Connect'] = pd.to_numeric(data['Connect'], errors='coerce')
data.loc[pd.isna(data['Connect']), 'Connect'] = np.nan
data['Connect'] = data['Connect'].astype('Int64')

data.dtypes

display(data)

data['responseCode'].fillna(501, inplace=True)
data.bytes.unique()

data.dtypes

import pandas as pd
from sklearn.preprocessing import LabelEncoder

categorical_columns = ['label', 'threadName', 'dataType','success','URL']

# Initialize the LabelEncoder
label_encoder = LabelEncoder()

# Encode each categorical column in the DataFrame
for col in categorical_columns:
    data[col + '_encoded'] = label_encoder.fit_transform(data[col])


# Now, each categorical column in the DataFrame has been replaced with its encoded numerical values
from sklearn.preprocessing import LabelEncoder

# Initialize the label encoder
label_encoder = LabelEncoder()

# Encode the labels
data['label_encoded'] = label_encoder.fit_transform(data['label'])

data.dtypes

data.drop(columns=[ "URL","success" , "dataType","threadName","label"], inplace=True)

display(data)

# Fit the scaler to the numerical features and transform them
from sklearn.preprocessing import MinMaxScaler

numerical_features = ['elapsed', 'responseCode', 'bytes', 'sentBytes', 'grpThreads', 'Latency', 'Connect', 'label_encoded', 'threadName_encoded', 'dataType_encoded', 'success_encoded', 'URL_encoded']

# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Fit the scaler to the numerical features and transform them
data[numerical_features] = scaler.fit_transform(data[numerical_features])

# Reshape each row of data into a 3D tensor with dimensions (time steps, features, 1)
reshaped_data = np.expand_dims(data.values, axis=2)

display(data)

data.shape

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

# X shape: (num_samples, num_features), y shape: (num_samples, num_targets)
feature_columns = ['elapsed', 'responseCode', 'bytes', 'sentBytes', 'grpThreads', 'Latency', 'Connect', 'label_encoded', 'threadName_encoded', 'dataType_encoded', 'success_encoded', 'URL_encoded']
target_columns = ['elapsed', 'responseCode', 'bytes', 'sentBytes', 'grpThreads', 'Latency', 'Connect', 'label_encoded', 'threadName_encoded', 'dataType_encoded', 'success_encoded', 'URL_encoded']

# Check for missing values in X and y
missing_X = data[feature_columns].isnull().sum()
missing_y = data[target_columns].isnull().sum()

# Fill missing values in X (features)
X_filled = data[feature_columns].fillna(data[feature_columns].mean())

# Fill missing values in y (target variables)
y_filled = data[target_columns].fillna(data[target_columns].mean())

# Split the data into features (X) and targets (y)
X = X_filled.values
y = y_filled.values

# Data Preprocessing with MinMaxScaler
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# Split the data into training, validation, and test sets
X_train, X_val_test, y_train, y_val_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, random_state=42)

# Reshape data for 1D CNN input (samples, timesteps, features)
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))

# Define CNN architecture
model = Sequential([
    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Conv1D(filters=32, kernel_size=3, activation='relu'),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(64, activation='relu'),
    Dense(y_train.shape[1])  # Number of output neurons equals the number of target variables
])

# Define the learning rate
learning_rate = 0.001

# Compile the model with the Adam optimizer and specified learning rate
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error')

# Define the data generator function
from tensorflow.data import Dataset

def batchGen(features, targets, batch_size, validation_flag):
    num_samples = features.shape[0]
    dataset = Dataset.from_tensor_slices((features, targets))

    # Shuffle the dataset if it's for training
    if not validation_flag:
        dataset = dataset.shuffle(buffer_size=num_samples)

    dataset = dataset.batch(batch_size).repeat()  # Repeat the dataset indefinitely

    # Create an iterator for the dataset
    iterator = iter(dataset)

    while True:
        batch_features, batch_targets = iterator.get_next()
        yield batch_features, batch_targets


# Define the number of steps per epoch and validation steps
steps_per_epoch = len(X_train) // 64
validation_steps = len(X_val) // 64

# Train the model
history = model.fit(
    batchGen(X_train, y_train, batch_size=162, validation_flag=0),
    steps_per_epoch=len(X_train) // 64,  # Assuming batch size of 64
    epochs=20,
    validation_data=batchGen(X_val, y_val, batch_size=162, validation_flag=1),
    validation_steps=len(X_val) // 64  # Assuming batch size of 64
)


model.save('model.h5')


print('model saved')

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['Training', 'Validation'])
plt.ylim([0, 1])
plt.title('Loss')
plt.xlabel('Epoch')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['Training', 'Validation'])
plt.ylim([-0.002, 0.025])
plt.title('Loss')
plt.xlabel('Epoch')
plt.xlim(0, 2.50)  # Zoom in on epochs
plt.show()

# Load the saved model
from tensorflow.keras.models import load_model

model = load_model('model.h5')
import pandas as pd
from google.colab import drive

predictiondata=pd.read_csv("/content/drive/MyDrive//SoftwareTesting.csv", low_memory=False)

predictiondata = predictiondata.sample(frac=0.5)

display(predictiondata)

predictiondata.drop(columns=[ "timeStamp","failureMessage" , "allThreads","responseMessage","IdleTime"], inplace=True)
display(predictiondata)

predictiondata['responseCode'].replace('Non HTTP response code: org.apache.http.conn.HttpHostConnectException', '500', inplace=True)
#Code 500 is for HIGH Load

import numpy as np

# Convert 'elapsed' column to numeric, coercing non-numeric values to NaN
predictiondata['elapsed'] = pd.to_numeric(predictiondata['elapsed'], errors='coerce')
# Replace NaN values with np.nan
predictiondata.loc[pd.isna(predictiondata['elapsed']), 'elapsed'] = np.nan
# Convert 'elapsed' column to int64 predictiondatatype
predictiondata['elapsed'] = predictiondata['elapsed'].astype('Int64')


predictiondata['responseCode'] = pd.to_numeric(predictiondata['responseCode'], errors='coerce')
predictiondata.loc[pd.isna(predictiondata['responseCode']), 'responseCode'] = np.nan
predictiondata['responseCode'] = predictiondata['responseCode'].astype('Int64')

predictiondata['bytes'] = pd.to_numeric(predictiondata['bytes'], errors='coerce')
predictiondata.loc[pd.isna(predictiondata['bytes']), 'bytes'] = np.nan
predictiondata['bytes'] = predictiondata['bytes'].astype('Int64')

predictiondata['sentBytes'] = pd.to_numeric(predictiondata['sentBytes'], errors='coerce')
predictiondata.loc[pd.isna(predictiondata['sentBytes']), 'sentBytes'] = np.nan
predictiondata['sentBytes'] = predictiondata['sentBytes'].astype('Int64')

predictiondata['grpThreads'] = pd.to_numeric(predictiondata['grpThreads'], errors='coerce')
predictiondata.loc[pd.isna(predictiondata['grpThreads']), 'grpThreads'] = np.nan
predictiondata['grpThreads'] = predictiondata['grpThreads'].astype('Int64')

predictiondata['Latency'] = pd.to_numeric(predictiondata['Latency'], errors='coerce')
predictiondata.loc[pd.isna(predictiondata['Latency']), 'Latency'] = np.nan
predictiondata['Latency'] = predictiondata['Latency'].astype('Int64')

predictiondata['Connect'] = pd.to_numeric(predictiondata['Connect'], errors='coerce')
predictiondata.loc[pd.isna(predictiondata['Connect']), 'Connect'] = np.nan
predictiondata['Connect'] = predictiondata['Connect'].astype('Int64')

import pandas as pd
from sklearn.preprocessing import LabelEncoder


categorical_columns = ['label', 'threadName', 'dataType','success','URL']

# Initialize the LabelEncoder
label_encoder = LabelEncoder()

# Encode each categorical column in the predictiondataFrame
for col in categorical_columns:
    predictiondata[col + '_encoded'] = label_encoder.fit_transform(predictiondata[col])

# Now, each categorical column in the predictiondataFrame has been replaced with its encoded numerical values
from sklearn.preprocessing import LabelEncoder

# Initialize the label encoder
label_encoder = LabelEncoder()

# Encode the labels
predictiondata['label_encoded'] = label_encoder.fit_transform(predictiondata['label'])

predictiondata.drop(columns=[ "URL","success" , "dataType","threadName","label"], inplace=True)

from sklearn.preprocessing import MinMaxScaler

numerical_features = ['elapsed', 'responseCode', 'bytes', 'sentBytes', 'grpThreads', 'Latency', 'Connect', 'label_encoded', 'threadName_encoded', 'dataType_encoded', 'success_encoded', 'URL_encoded']

# Initialize the MinMaxScaler
scaler = MinMaxScaler()

# Fit the scaler to the numerical features and transform them
predictiondata[numerical_features] = scaler.fit_transform(predictiondata[numerical_features])


# Reshape each row of data into a 3D tensor with dimensions (time steps, features, 1)
reshaped_data = np.expand_dims(predictiondata.values, axis=2)



# Make predictions on the entire DataFrame
predictions = model.predict(predictiondata)


predictions_scaled = predictions
predictions_original_scale = scaler_y.inverse_transform(predictions_scaled)

# Now `predictions_original_scale` contains the predicted values in the original scale

import pandas as pd

# Create a new DataFrame for predictions
predictions_df = pd.DataFrame(predictions_original_scale, columns=target_columns)

# Save the predictions DataFrame to a CSV file
predictions_df.to_csv('predictions.csv', index=False)

import matplotlib.pyplot as plt


columns_to_plot = ['elapsed','responseCode','bytes','sentBytes','grpThreads','Latency','Connect','label_encoded','threadName_encoded','dataType_encoded','success_encoded','URL_encoded']  # List of column names to plot

# Plot histograms for each column
for column in columns_to_plot:
    plt.hist(data[column], bins=10, alpha=0.5, label=column)

# Add labels and title
plt.xlabel(', '.join(columns_to_plot))
plt.ylabel('Frequency')
plt.title('Histogram of Multiple Columns for Actual Data')
plt.legend()

# Show plot
plt.show()
print(" ")

columns_to_plot = ['elapsed','responseCode','bytes','sentBytes','grpThreads','Latency','Connect','label_encoded','threadName_encoded','dataType_encoded','success_encoded','URL_encoded']  # List of column names to plot

# Plot histograms for each column
for column in columns_to_plot:
    plt.hist(predictions_df[column], bins=10, alpha=0.5, label=column)  # Adjust bins and alpha as needed

# Add labels and title
plt.xlabel(', '.join(columns_to_plot))
plt.ylabel('Frequency')
plt.title('Histogram of Multiple Columns for Predicted data')
plt.legend()

# Show plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['elapsed']

# Extract the column from DataFrame 2
x2 = predictions_df['elapsed']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('Elapsed Time')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted Elapsed Time')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['responseCode']

# Extract the column from DataFrame 2
x2 = predictions_df['responseCode']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('responseCode')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted responseCode')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['Latency']

# Extract the column from DataFrame 2
x2 = predictions_df['Latency']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('Latency')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted Latency')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns

# Extract the column from DataFrame 1
x1 = data['Connect']

# Extract the column from DataFrame 2
x2 = predictions_df['Connect']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('Connect')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted Connect')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['bytes']

# Extract the column from DataFrame 2
x2 = predictions_df['bytes']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('bytes')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted bytes')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['sentBytes']

# Extract the column from DataFrame 2
x2 = predictions_df['sentBytes']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('sentBytes')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted sentBytes')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['grpThreads']

# Extract the column from DataFrame 2
x2 = predictions_df['grpThreads']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('grpThreads')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted grpThreads')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['label_encoded']

# Extract the column from DataFrame 2
x2 = predictions_df['label_encoded']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('label_encoded')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted label')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['threadName_encoded']

# Extract the column from DataFrame 2
x2 = predictions_df['threadName_encoded']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('threadName_encoded')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted threadName')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['dataType_encoded']

# Extract the column from DataFrame 2
x2 = predictions_df['dataType_encoded']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('dataType_encoded')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted dataType')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['success_encoded']

# Extract the column from DataFrame 2
x2 = predictions_df['success_encoded']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('success')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted Success')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()

import seaborn as sns


# Extract the column from DataFrame 1
x1 = data['URL_encoded']

# Extract the column from DataFrame 2
x2 = predictions_df['URL_encoded']

# Plot KDE plots for actual and predicted data
sns.kdeplot(x1, color='blue', label='Actual', linewidth=2)  # Plot KDE for actual data in blue
sns.kdeplot(x2, color='red', label='Predicted', linewidth=2)  # Plot KDE for predicted data in red

# Add grid lines
plt.grid(True)

# Add labels and title
plt.xlabel('URL_encoded')  # Modify as needed
plt.ylabel('Density')  # Modify as needed
plt.title('Kernel Density Estimate of Actual and Predicted URL')  # Modify as needed
plt.legend()  # Show legend

# Show the plot
plt.show()